{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8- MultiVariate MultiOutput MultiStep TS Forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLp1VIcpSueexMH2KE3KCq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MWFK/TimeSeries_Sequence_with_TensorFlow/blob/main/8-%20MultiVariate_MultiOutput_MultiStep_TS_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definitions\n",
        "\n",
        "\n",
        "**Multivariate time-series** \n",
        "\n",
        "has more than one time-dependent variable. Each variable depends not only on its past values but also has some dependency on other variables. This dependency is used for forecasting future values. In this case, there are multiple variables to be considered to optimally predict temperature.\n",
        "\n",
        "\n",
        "**Multioutput regression**\n",
        "\n",
        "involve predicting two or more numerical values given an input example. An example might be to predict a coordinate given an input, e.g. predicting x and y values.\n",
        "\n",
        "\n",
        "**Multistep prediction**\n",
        "\n",
        "is the task of predicting a sequence of values in a time series. A typical approach, known as multi-stage prediction, is to apply a predictive model step-by-step and use the predicted value of the current time step to determine its value in the next time step."
      ],
      "metadata": {
        "id": "aZBCAyEjRSC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge\n",
        "\n",
        "**TIME SERIES QUESTION**\n",
        "\n",
        "Build and train a neural network to predict time indexed variables of\n",
        "the multivariate house hold electric power consumption time series dataset.\n",
        "Using a window of past 24 observations of the 7 variables, the model\n",
        "should be trained to predict the next 24 observations of the 7 variables.\n",
        "\n",
        " ==============================================================================\n",
        "\n",
        "**ABOUT THE DATASET**\n",
        "\n",
        "Original Source:\n",
        "https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption\n",
        "\n",
        "The original 'Individual House Hold Electric Power Consumption Dataset'\n",
        "has Measurements of electric power consumption in one household with\n",
        "a one-minute sampling rate over a period of almost 4 years.\n",
        "\n",
        "Different electrical quantities and some sub-metering values are available.\n",
        "\n",
        "For the purpose of the examination we have provided a subset containing\n",
        "the data for the first 60 days in the dataset. We have also cleaned the\n",
        "dataset beforehand to remove missing values. The dataset is provided as a\n",
        "csv file in the project.\n",
        "\n",
        "The dataset has a total of 7 features ordered by time.\n",
        "\n",
        "==============================================================================\n",
        "\n",
        "**INSTRUCTIONS**\n",
        "\n",
        "Complete the code in following functions:\n",
        "\n",
        "1. windowed_dataset()\n",
        "2. solution_model()\n",
        "\n",
        "The model input and output shapes must match the following\n",
        "specifications.\n",
        "\n",
        "1. Model input_shape must be (BATCH_SIZE, N_PAST = 24, N_FEATURES = 7),\n",
        "   since the testing infrastructure expects a window of past N_PAST = 24\n",
        "   observations of the 7 features to predict the next 24 observations of\n",
        "   the same features.\n",
        "\n",
        "2. Model output_shape must be (BATCH_SIZE, N_FUTURE = 24, N_FEATURES = 7)\n",
        "\n",
        "3. DON'T change the values of the following constants\n",
        "   N_PAST, N_FUTURE, SHIFT in the windowed_dataset()\n",
        "   BATCH_SIZE in solution_model() (See code for additional note on\n",
        "   BATCH_SIZE).\n",
        "\n",
        "4. Code for normalizing the data is provided - DON't change it.\n",
        "   Changing the normalizing code will affect your score.\n",
        "\n",
        "HINT: Your neural network must have a validation MAE of approximately 0.055 or less on the normalized validation dataset for top marks.\n",
        "\n",
        "WARNING: Do not use lambda layers in your model, they are not supported\n",
        "on the grading infrastructure.\n",
        "\n",
        "WARNING: If you are using the GRU layer, it is advised not to use the\n",
        "'recurrent_dropout' argument (you can alternatively set it to 0),\n",
        "since it has not been implemented in the cuDNN kernel and may\n",
        "result in much longer training times.\n"
      ],
      "metadata": {
        "id": "KkZ39W01TrVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libs"
      ],
      "metadata": {
        "id": "6IpATluJU6yX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Uust-arAzdiP"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "8HapTuEVVIMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function downloads and extracts the dataset to the directory that\n",
        "# contains this file.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "# (unless you need to change https to http)\n",
        "def download_and_extract_data():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/household_power.zip'\n",
        "    urllib.request.urlretrieve(url, 'household_power.zip')\n",
        "    with zipfile.ZipFile('/content/household_power.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "        \n",
        "download_and_extract_data()"
      ],
      "metadata": {
        "id": "Z7RLS2JdVDcN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/household_power_consumption.csv', sep=',',infer_datetime_format=True, index_col='datetime', header=0)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "g6ICd8X0WTzE",
        "outputId": "60285a07-1752-4d13-bda2-fb24e18db430"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(86400, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f227782b-b6e1-4ec6-a6bf-de864d9fdebe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:24:00</th>\n",
              "      <td>4.216</td>\n",
              "      <td>0.418</td>\n",
              "      <td>234.84</td>\n",
              "      <td>18.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:25:00</th>\n",
              "      <td>5.360</td>\n",
              "      <td>0.436</td>\n",
              "      <td>233.63</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:26:00</th>\n",
              "      <td>5.374</td>\n",
              "      <td>0.498</td>\n",
              "      <td>233.29</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:27:00</th>\n",
              "      <td>5.388</td>\n",
              "      <td>0.502</td>\n",
              "      <td>233.74</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:28:00</th>\n",
              "      <td>3.666</td>\n",
              "      <td>0.528</td>\n",
              "      <td>235.68</td>\n",
              "      <td>15.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f227782b-b6e1-4ec6-a6bf-de864d9fdebe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f227782b-b6e1-4ec6-a6bf-de864d9fdebe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f227782b-b6e1-4ec6-a6bf-de864d9fdebe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     Global_active_power  ...  Sub_metering_3\n",
              "datetime                                  ...                \n",
              "2006-12-16 17:24:00                4.216  ...            17.0\n",
              "2006-12-16 17:25:00                5.360  ...            16.0\n",
              "2006-12-16 17:26:00                5.374  ...            17.0\n",
              "2006-12-16 17:27:00                5.388  ...            17.0\n",
              "2006-12-16 17:28:00                3.666  ...            17.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalisation"
      ],
      "metadata": {
        "id": "uwx-XwssVaKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function normalizes the dataset using min max scaling.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "def normalize_series(data, min, max):\n",
        "    data = data - min\n",
        "    data = data / max\n",
        "    return data"
      ],
      "metadata": {
        "id": "bmZ_6Z6NVVIz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation of the Dataset Windowing"
      ],
      "metadata": {
        "id": "YxOn684iZge4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================== expand_dims == Falqse ================================\n",
        "\n",
        "# get the slices of an array in the form of objects \n",
        "# tf.data.Dataset.from_tensor_slices([[5, 10], [3, 6]]) will become == [5,10], [3,6]\n",
        "ds = tf.data.Dataset.from_tensor_slices(df.head(12))\n",
        "# tf.print(ds)\n",
        "# print(list(ds.as_numpy_iterator()),'\\n\\n')\n",
        "\n",
        "\n",
        "# ======================== expand_dims == True ================================\n",
        "\n",
        "ds = tf.expand_dims(df.head(12), axis=-1)    \n",
        "# tf.print(ds,'\\n\\n')\n",
        "\n",
        "# get the slices of an array in the form of objects \n",
        "# tf.data.Dataset.from_tensor_slices([[5, 10], [3, 6]]) will become == [5,10], [3,6]\n",
        "ds = tf.data.Dataset.from_tensor_slices(ds)\n",
        "# tf.print(ds)\n",
        "# list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "id": "ADv7_AVTZU_H"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.window(size=6, shift=1, drop_remainder=True)\n",
        "# tf.print(ds)"
      ],
      "metadata": {
        "id": "ZXaYAHp_aiUh"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.flat_map(lambda w: w.batch(6))\n",
        "# tf.print(ds)\n",
        "# tf.print(list(ds.as_numpy_iterator()))"
      ],
      "metadata": {
        "id": "-SkCb2QKd-W7"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(lambda x : (x[:-7], x[-7:, :1])) \n",
        "tf.print(ds)\n",
        "tf.print(list(ds.as_numpy_iterator()))"
      ],
      "metadata": {
        "id": "uSvnE8VSh7pi",
        "outputId": "09ad877d-424d-467e-9710-9d57258dd3b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MapDataset shapes: ((None, 7, 1), (None, 1, 1)), types: (tf.float64, tf.float64)>\n",
            "[(array([], shape=(0, 7, 1), dtype=float64),\n",
            "  array([[[4.216]],\n",
            "\n",
            "       [[5.36 ]],\n",
            "\n",
            "       [[5.374]],\n",
            "\n",
            "       [[5.388]],\n",
            "\n",
            "       [[3.666]],\n",
            "\n",
            "       [[3.52 ]]])),\n",
            " (array([], shape=(0, 7, 1), dtype=float64),\n",
            "  array([[[5.36 ]],\n",
            "\n",
            "       [[5.374]],\n",
            "\n",
            "       [[5.388]],\n",
            "\n",
            "       [[3.666]],\n",
            "\n",
            "       [[3.52 ]],\n",
            "\n",
            "       [[3.702]]])),\n",
            " (array([], shape=(0, 7, 1), dtype=float64),\n",
            "  array([[[5.374]],\n",
            "\n",
            "       [[5.388]],\n",
            "\n",
            "       [[3.666]],\n",
            "\n",
            "       [[3.52 ]],\n",
            "\n",
            "       [[3.702]],\n",
            "\n",
            "       [[3.7  ]]])),\n",
            " (array([], shape=(0, 7, 1), dtype=float64),\n",
            "  array([[[5.388]],\n",
            "\n",
            "       [[3.666]],\n",
            "\n",
            "       [[3.52 ]],\n",
            "\n",
            "       [[3.702]],\n",
            "\n",
            "       [[3.7  ]],\n",
            "\n",
            "       [[3.668]]])),\n",
            " (array([], shape=(0, 7, 1), dtype=float64),\n",
            "  array([[[3.666]],\n",
            "\n",
            "       [[3.52 ]],\n",
            "\n",
            "       [[3.702]],\n",
            "\n",
            "       [[3.7  ]],\n",
            "\n",
            "       [[3.668]],\n",
            "\n",
            "       [[3.662]]])),\n",
            " (array([], shape=(0, 7, 1), dtype=float64),\n",
            "  array([[[3.52 ]],\n",
            "\n",
            "       [[3.702]],\n",
            "\n",
            "       [[3.7  ]],\n",
            "\n",
            "       [[3.668]],\n",
            "\n",
            "       [[3.662]],\n",
            "\n",
            "       [[4.448]]])),\n",
            " (array([], shape=(0, 7, 1), dtype=float64),\n",
            "  array([[[3.702]],\n",
            "\n",
            "       [[3.7  ]],\n",
            "\n",
            "       [[3.668]],\n",
            "\n",
            "       [[3.662]],\n",
            "\n",
            "       [[4.448]],\n",
            "\n",
            "       [[5.412]]]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Windowing Dataset"
      ],
      "metadata": {
        "id": "-_S11T9pVhhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is used to map the unwindowed time series dataset to a\n",
        "# windowed dataset so as to prepare it for training and validation.\n",
        "# A window of features are constructed by shifting the window's starting\n",
        "# position forward, one at a time (indicated by shift=1).\n",
        "# For a window of 'n_past' number of observations of all time indexed variables in\n",
        "# the dataset, the target for the window is the next 'n_future' number\n",
        "# of observations of these variables, after the end of the window.\n",
        "\n",
        "# COMPLETE THE CODE IN THE FOLLOWING FUNCTION.\n",
        "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
        "\n",
        "    ds = tf.expand_dims(series, axis=-1)         # Convert the 2D DataFrame to 3D Tensor => from (table, rows, columns) to (rows, columns, 1) ==> From (17097, 5) to (17097, 5, 1) \n",
        "    ds = tf.data.Dataset.from_tensor_slices(ds)  # Create a tensor => from (17097, 5, 1) to (5,1)\n",
        "\n",
        "    # This line converts the dataset into a windowed dataset where a\n",
        "    # window consists of both the observations to be included as features\n",
        "    # and the targets.\n",
        "\n",
        "    # Don't change the shift parameter. The test windows are\n",
        "    # created with the specified shift and hence it might affect your\n",
        "    # scores. Calculate the window size so that based on\n",
        "    # the past 24 observations\n",
        "    # (observations at time steps t=1,t=2,...t=24) of the 7 variables\n",
        "    # in the dataset, you predict the next 24 observations\n",
        "    # (observations at time steps t=25,t=26....t=48) of the 7 variables\n",
        "    # of the dataset.\n",
        "\n",
        "    # Hint: Each window should include both the past observations and\n",
        "    # the future observations which are to be predicted. Calculate the\n",
        "    # window size based on n_past and n_future.\n",
        "\n",
        "    ds = ds.window(size=n_past + n_future,# YOUR CODE HERE,\n",
        "                   shift=shift, drop_remainder=True)\n",
        "\n",
        "    # flatten a dataset of batches into a dataset of their elements:\n",
        "    # and convert it from tensors to a  a = {[1,2,3], [6,7,8], [10,11,36]} ==> a.flat_map(lambda x: Dataset.from_tensor_slices(x)) == {[1,2,3,6,7,8,10,11,36]}\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#flat_map\n",
        "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
        "\n",
        "    # Now each window in the dataset has n_past and n_future observations.\n",
        "    # This line maps each window to the form (n_past observations,\n",
        "    # n_future observations) in the format needed for training the model.\n",
        "    # Note: You can use a lambda function to map each window in the\n",
        "    # dataset to it's respective (features, targets).\n",
        "\n",
        "    # x[:-n_horizon]     == x[All batches except for the last one]  ==> X\n",
        "    # x[-n_horizon:, :1] == x[The Last batch of features]           ==> y\n",
        "    ds = ds.map(lambda x : (x[:-n_future], x[-n_future:, :1])) \n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "t7x2A3qNVduX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling"
      ],
      "metadata": {
        "id": "1FPQgbw9V8Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function loads the data from csv file, normalizes the data and\n",
        "# splits the dataset into train and validation data. It also uses the\n",
        "# 'windowed_dataset' to split the data into windows of observations and\n",
        "# targets. Finally it defines, compiles and trains a neural network.\n",
        "# This function returns the trained model.\n",
        "\n",
        "# COMPLETE THE CODE IN THE FOLLOWING FUNCTION.\n",
        "def solution_model():\n",
        "    # Downloads and extracts the dataset to the directory that contains this file.\n",
        "    # download_and_extract_data()\n",
        "    # Reads the dataset from the csv.\n",
        "    df = pd.read_csv('/content/household_power_consumption.csv', sep=',',infer_datetime_format=True, index_col='datetime', header=0)\n",
        "\n",
        "    # Number of features in the dataset. We use all features as predictors to\n",
        "    # predict all features at future time steps.\n",
        "    N_FEATURES = len(df.columns)\n",
        "\n",
        "    # Normalizes the data\n",
        "    data = df.values\n",
        "    split_time = int(len(data) * 0.5)\n",
        "    data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
        "\n",
        "    # Splits the data into training and validation sets.\n",
        "    x_train = data[:split_time]\n",
        "    x_valid = data[split_time:]\n",
        "\n",
        "    # DO NOT CHANGE 'BATCH_SIZE' IF YOU ARE USING STATEFUL LSTM/RNN/GRU.\n",
        "    # THE TEST WILL FAIL TO GRADE YOUR SCORE IN SUCH CASES.\n",
        "    # In other cases, it is advised not to change the batch size since it\n",
        "    # might affect your final scores. While setting it to a lower size\n",
        "    # might not do any harm, higher sizes might affect your scores.\n",
        "    BATCH_SIZE = 32  # ADVISED NOT TO CHANGE THIS\n",
        "    # Explanation of the batch_size \n",
        "    # https://stackoverflow.com/questions/42998989/batch-size-in-tensorflow-understanding-the-concept\n",
        "\n",
        "    # DO NOT CHANGE N_PAST, N_FUTURE, SHIFT. The tests will fail to run\n",
        "    # on the server.\n",
        "    # Number of past time steps based on which future observations should be\n",
        "    # predicted\n",
        "    N_PAST = 24  # DO NOT CHANGE THIS\n",
        "\n",
        "    # Number of future time steps which are to be predicted.\n",
        "    N_FUTURE = 24  # DO NOT CHANGE THIS\n",
        "\n",
        "    # By how many positions the window slides to create a new window\n",
        "    # of observations.\n",
        "    SHIFT = 1  # DO NOT CHANGE THIS\n",
        "\n",
        "    # Code to create windowed train and validation datasets.\n",
        "    # Complete the code in windowed_dataset.\n",
        "    train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE, n_past=N_PAST, n_future=N_FUTURE, shift=SHIFT)\n",
        "    valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE, n_past=N_PAST, n_future=N_FUTURE, shift=SHIFT)\n",
        "\n",
        "    # Code to define your model.\n",
        "    model = tf.keras.models.Sequential([\n",
        "\n",
        "        # ADD YOUR LAYERS HERE.\n",
        "        # Use this for random batch_size input_shape=(none, N_PAST, N_FEATURES) or \n",
        "        # input_shape=(BATCH_SIZE, N_PAST, N_FEATURES) for fixed batch size\n",
        "        tf.keras.layers.Flatten(input_shape=(N_PAST, N_FEATURES)), \n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        #tf.keras.layers.Dense(n_horizon) https://www.kaggle.com/nicholasjhana/multi-variate-time-series-forecasting-tensorflow\n",
        "\n",
        "        # If you don't follow the instructions in the following comments,\n",
        "        # tests will fail to grade your code:\n",
        "        # Whatever your first layer is, the input shape will be\n",
        "        # (BATCH_SIZE, N_PAST = 24, N_FEATURES = 7)\n",
        "        # The model must have an output shape of\n",
        "        # (BATCH_SIZE, N_FUTURE = 24, N_FEATURES = 7).\n",
        "        # Make sure that there are N_FEATURES = 7 neurons in the final dense\n",
        "        # layer since the model predicts 7 features.\n",
        "\n",
        "        # WARNING: If you are using the GRU layer, it is advised not to use the\n",
        "        # 'recurrent_dropout' argument (you can alternatively set it to 0),\n",
        "        # since it has not been implemented in the cuDNN kernel and may\n",
        "        # result in much longer training times.\n",
        "        tf.keras.layers.Dense(N_FEATURES)\n",
        "    ])\n",
        "\n",
        "    # Code to train and compile the model\n",
        "    loss = tf.keras.losses.Huber()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)# YOUR CODE HERE\n",
        "    model.compile(loss=loss, optimizer='adam', metrics=['mae'])\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    num_epochs = 10\n",
        "    model.fit(x=train_set, validation_data=valid_set, epochs=num_epochs, verbose=2)\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "QKyYAbFnXMV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution"
      ],
      "metadata": {
        "id": "UcJ4khlDWpjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7ykONUjWOfm",
        "outputId": "ba11e935-b2c7-45d4-e371-58ca229371cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1349/1349 - 27s - loss: 0.0067 - mae: 0.0766 - val_loss: 0.0059 - val_mae: 0.0681 - 27s/epoch - 20ms/step\n",
            "Epoch 2/10\n",
            "1349/1349 - 26s - loss: 0.0047 - mae: 0.0646 - val_loss: 0.0048 - val_mae: 0.0604 - 26s/epoch - 19ms/step\n",
            "Epoch 3/10\n",
            "1349/1349 - 25s - loss: 0.0045 - mae: 0.0626 - val_loss: 0.0051 - val_mae: 0.0616 - 25s/epoch - 19ms/step\n",
            "Epoch 4/10\n",
            "1349/1349 - 25s - loss: 0.0044 - mae: 0.0616 - val_loss: 0.0048 - val_mae: 0.0596 - 25s/epoch - 18ms/step\n",
            "Epoch 5/10\n",
            "1349/1349 - 26s - loss: 0.0044 - mae: 0.0610 - val_loss: 0.0047 - val_mae: 0.0582 - 26s/epoch - 19ms/step\n",
            "Epoch 6/10\n",
            "1349/1349 - 25s - loss: 0.0043 - mae: 0.0606 - val_loss: 0.0046 - val_mae: 0.0583 - 25s/epoch - 18ms/step\n",
            "Epoch 7/10\n",
            "1349/1349 - 25s - loss: 0.0043 - mae: 0.0604 - val_loss: 0.0045 - val_mae: 0.0576 - 25s/epoch - 19ms/step\n",
            "Epoch 8/10\n",
            "1349/1349 - 25s - loss: 0.0043 - mae: 0.0601 - val_loss: 0.0045 - val_mae: 0.0582 - 25s/epoch - 18ms/step\n",
            "Epoch 9/10\n",
            "1349/1349 - 25s - loss: 0.0043 - mae: 0.0600 - val_loss: 0.0044 - val_mae: 0.0565 - 25s/epoch - 19ms/step\n",
            "Epoch 10/10\n",
            "1349/1349 - 25s - loss: 0.0043 - mae: 0.0599 - val_loss: 0.0045 - val_mae: 0.0567 - 25s/epoch - 19ms/step\n"
          ]
        }
      ]
    }
  ]
}